ğŸ“˜ Project Notes â€“ High-Concurrency Flash Sale System (Till Day 4 â€“ Before Redis)

1ï¸âƒ£ Overall Architecture
âœ… Built a Microservices-Based Backend
Separated system into:
User Service
Stock Service
Order Service

Each service:
Runs independently
Has its own database
Communicates via REST
Can scale independently

Architecture:
Client
  â†“
Order Service
  â†“
Stock Service
  â†“
PostgreSQL

2ï¸âƒ£ Infrastructure Setup
âœ… Docker-Based Environment
PostgreSQL container
Redis container (not used yet)
RabbitMQ container (not used yet)

Benefits:
Environment isolation
Easy reproducibility
Production-like setup

3ï¸âƒ£ Database Design
ğŸ—„ User Service
Table: users
Fields:
id (PK)
username (unique)
balance
created_at

ğŸ—„ Stock Service
Table: products
Fields:
id (PK)
name
price
stock
created_at
version (for optimistic locking)

Order Service
Table: orders
Fields:
id (PK)
user_id
product_id
quantity
order_status (SUCCESS)

4ï¸âƒ£ REST APIs Built
ğŸ“Œ User Service
Create user
Fetch user

ğŸ“Œ Stock Service
Create product
Get product
Reduce stock

ğŸ“Œ Order Service
Create order
Internally calls stock-service

Day 3: 
The Order Service was designed to communicate with the Stock Service using RestTemplate, ensuring that every order 
creation request first validated and reduced product stock before persisting the order. This introduced real-world 
service-to-service dependency handling, where HTTP responses such as 400 (Out of Stock) and 409 (High Traffic) were properly 
propagated instead of being incorrectly converted into generic 500 errors. Exception handling was refined to ensure accurate 
distributed error translation using Springâ€™s RestClientResponseException, which eliminated unexpected failures and made the API 
behavior production-consistent.

To handle high concurrency, optimistic locking was implemented at the database level using JPAâ€™s @Version annotation 
in the Product entity. This prevented lost updates and eliminated overselling by ensuring that concurrent updates to 
the same product row would fail safely if version mismatches occurred. Under load testing (simulating 20 parallel requests 
with limited stock), the system correctly prevented overselling and maintained data integrity. However, it exposed a 
key architectural limitation: heavy row-level contention in the database. Even with a retry mechanism (up to three attempts 
per request), high concurrency led to version conflicts, retry exhaustion, and partial stock utilization. This demonstrated 
that while optimistic locking ensures correctness, the database becomes a bottleneck under burst traffic conditions.

By this stage, the system had achieved strong consistency guarantees, safe distributed transaction behavior across services, 
and robust concurrency control using database-level mechanisms. It accurately modeled real-world flash sale challenges, 
including race conditions, contention management, and distributed error propagation. However, it also highlighted scalability 
constraints inherent in database-driven stock control, setting the stage for transitioning to an in-memory atomic stock management 
approach using Redis in the next phase of the architecture.


Day 4:
transitioned stock management from database-driven optimistic locking to Redis-based atomic control to improve scalability 
under high concurrency. Instead of relying on JPAâ€™s @Version mechanism to prevent overselling, we introduced Redis as an i
n-memory gatekeeper for stock validation. Using Spring Data Redis and StringRedisTemplate, product stock is now loaded into 
Redis and decremented atomically using the DECR operation whenever an order request arrives. This ensures that concurrent 
requests no longer compete at the database row level; Redis, being single-threaded and atomic by design, guarantees that only 
the available stock count can succeed while excess requests fail instantly. If a decrement results in a negative value, the operation 
is reverted and an â€œOut of Stockâ€ response is returned immediately. This architectural shift removes database contention, eliminates 
retry storms caused by version conflicts, and significantly improves system responsiveness under burst traffic. The database is no longer 
responsible for concurrency control and instead serves as a persistence layer, preparing the system for the next stageâ€”event-driven 
asynchronous consistency using message queues.

Day 5:
Tonight, we improved our Flash Sale System a lot and made it more like a real-world production system. We kept our three microservices 
separate â€” User Service, Stock Service, and Order Service â€” each with its own database and responsibility. Instead of using the database 
to control stock during high traffic, we moved stock handling to Redis, which allows us to reduce stock atomically and prevent overselling 
even when many requests come at the same time. This made the system faster and reduced pressure on the database. Then, we introduced RabbitMQ 
so that stock updates are sent as events instead of updating the database immediately. This means the system now works in an event-driven way 
and updates the database asynchronously. We also decided to follow eventual consistency, where Redis handles real-time stock control and the
 database gets updated in the background. After testing with multiple concurrent requests, we confirmed that extra orders were rejected 
 correctly and stock remained accurate. Overall, we moved from a simple CRUD project to a more scalable, high-concurrency microservices 
 system similar to how real flash sale platforms are designed.
